{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,\n",
    "    'axes.grid': True,\n",
    "    'axes.prop_cycle': plt.cycler(color=['k'])\n",
    "})\n",
    "import pandas as pd\n",
    "from uncertainties import ufloat as uf, unumpy as unp\n",
    "import uncertainties.umath as umath\n",
    "from collections import OrderedDict\n",
    "from pint import UnitRegistry\n",
    "import pint\n",
    "u = UnitRegistry()\n",
    "u.load_definitions(\"../units.txt\")\n",
    "u.setup_matplotlib()\n",
    "u.mpl_formatter = '{:L}'\n",
    "pint.set_application_registry(u)\n",
    "import pint_pandas\n",
    "# M_ = u.Measurement\n",
    "Q_ = u.Quantity\n",
    "def M_(val, err, unit):\n",
    "    if type(val) == list or type(val) == np.ndarray or type(val) == pd.Series:\n",
    "        if type(err) == list or type(err) == np.ndarray:\n",
    "            return Q_(np.array([uf(n, s) for (n, s) in zip(val, err)]), unit)\n",
    "        else:\n",
    "            return Q_(np.array([uf(n, err) for n in val]), unit)\n",
    "    else:\n",
    "        return u.Measurement(val, err, unit)\n",
    "\n",
    "def mk_numpy(arr, to):\n",
    "    if type(to) == str: to = u(to)\n",
    "    return np.array(list(map(lambda x: x.m_as(to), arr))) * to\n",
    "\n",
    "def np_split(arr):\n",
    "    return np.array([(i.n, i.s) for i in arr.magnitude]) * arr.units\n",
    "\n",
    "def errorbar(x, y):\n",
    "    x = np_split(x)\n",
    "    y = np_split(y)\n",
    "    # print(x[:, 0])\n",
    "    plt.errorbar(x[:, 0], y[:, 0], yerr=y[:, 1], xerr=x[:, 1])\n",
    "    plt.gca().xaxis.set_units(x.units)\n",
    "    plt.gca().yaxis.set_units(y.units)\n",
    "\n",
    "def plot(x, y):\n",
    "    x = np_split(x)\n",
    "    y = np_split(y)\n",
    "    # print(x[:, 0])\n",
    "    plt.plot(x[:, 0], y[:, 0])\n",
    "\n",
    "def polyfit(x, y):\n",
    "    x = np_split(x)\n",
    "    y = np_split(y)\n",
    "    ((k, b), cov) = np.polyfit(x[:, 0].magnitude, y[:, 0].magnitude, deg=1, w=1/y[:, 1].magnitude, cov=True)\n",
    "    err = np.sqrt(np.diag(cov))\n",
    "    return (M_(k, err[0], (1 * y.units * (x.units)**-1)).to_reduced_units(), M_(b, err[1], (1 * y.units)))\n",
    "\n",
    "def minmax(x):\n",
    "    x = np_split(x)\n",
    "    return mk_numpy([x[:, 0].min(), x[:, 0].max()], x.units)\n",
    "\n",
    "def hack(x):\n",
    "    return [i for i in x]\n",
    "\n",
    "_ = mk_numpy([1*u.г], 'г') # test\n",
    "_ = M_(1, 1, 'с')\n",
    "_ = M_([1, 2], 1, 'с')\n",
    "_ = M_([1, 2], [1, 2], 'с')\n",
    "\n",
    "try:\n",
    "    _PINT = _PINT\n",
    "except:\n",
    "    _PINT = False\n",
    "if not _PINT:\n",
    "    _PINT = True\n",
    "    @pint.register_unit_format(\"typst\")\n",
    "    def format_unit_typst(unit, registry, **options):\n",
    "        return \" dot \".join((f'\"{u}\"^({p})' if p != 1 else f'\"{u}\"')for u, p in unit.items())\n",
    "u.default_format = \"typst\"\n",
    "\n",
    "def load(path):\n",
    "    dfs = pd.read_excel(path, engine=\"odf\", header=[0,1], sheet_name=None)\n",
    "    return {\n",
    "        sheet: pd.DataFrame({\n",
    "            c[0]: pint_pandas.PintArray(df[c[0]].to_numpy().flatten(), c[1]) if str(c[1]) != '1' else df[c[0]].to_numpy().flatten()\n",
    "            # if str(c[1]) != '1' else df[c[0]].to_numpy().flatten()\n",
    "            for c in df.columns\n",
    "        }) for (sheet, df) in dfs.items()\n",
    "    }\n",
    "\n",
    "def make_cols(df, cols):\n",
    "    from itertools import zip_longest\n",
    "    import warnings\n",
    "    c0 = df.columns.get_level_values(0)\n",
    "    if len(cols) > len(c0):\n",
    "        warnings.warn(\"Too many columns\")\n",
    "        cols = cols[:len(c0)]\n",
    "    try:\n",
    "        c1 = df.columns.get_level_values(1)\n",
    "    except:\n",
    "        c1 = ['']*len(c0)\n",
    "    df.columns = pd.MultiIndex.from_tuples(zip(c0, [col if col else cc1 for col, cc1 in zip_longest(cols, c1)]))\n",
    "\n",
    "PA_ = pint_pandas.PintArray\n",
    "\n",
    "def save():\n",
    "    _temptype = type(M_(1.0, 0.1, \"м\"))\n",
    "    _temptype1 = type(Q_(1.0, \"м\"))\n",
    "    import inspect\n",
    "    import toml\n",
    "    import warnings\n",
    "    class MyEncoder(toml.TomlNumpyEncoder):\n",
    "        def __init__(self, _dict=dict, preserve=False):\n",
    "            import uncertainties\n",
    "            import pint\n",
    "            super(MyEncoder, self).__init__(_dict, preserve)\n",
    "            self.dump_funcs[uncertainties.core.Variable] = self._dump_ufloat\n",
    "            self.dump_funcs[uncertainties.core.AffineScalarFunc] = self._dump_ufloat\n",
    "            self.dump_funcs[pint.facets.measurement.objects.Measurement] = self._dump_pint\n",
    "            self.dump_funcs[_temptype] = self._dump_pint\n",
    "            self.dump_funcs[_temptype1] = self._dump_pint\n",
    "            self.dump_funcs[pd.DataFrame] = self._dump_pandas\n",
    "        def _dump_ufloat(self, v):\n",
    "            return self.dump_inline_table({\"n\": v.n, \"s\": v.s, \"r\": str(v).replace(\"+/-\", \"±\")})\n",
    "        def _dump_pint(self, v):\n",
    "            n, s = str(v.magnitude).split(\"+/-\")\n",
    "            u = f'{v.units:typst}'\n",
    "            return self.dump_inline_table({\n",
    "                \"n\": f'${n}space{u}$',\n",
    "                \"s\": f'${s}space{u}$',\n",
    "                \"r\": f'${n} plus.minus {s}space{u}$'\n",
    "            })\n",
    "        def _dump_pandas(self, v):\n",
    "            cs = v.columns.to_frame().to_numpy()\n",
    "            if cs.shape[1] == 3:\n",
    "                return self.dump_inline_table({\n",
    "                    \"cols\": [f\"${c1}, {c2}$\" if c2 != \"No Unit\" else f\"${c1}$\" for c1, c2 in zip(v.columns.get_level_values(1), v.columns.get_level_values(2))],\n",
    "                    \"vals\": v.values\n",
    "                })\n",
    "            if cs.shape[1] == 2:\n",
    "                return self.dump_inline_table({\n",
    "                    \"cols\": v.columns.get_level_values(1),\n",
    "                    \"vals\": v.values\n",
    "                })\n",
    "            warnings.warn(\"Unknown column index shape\")\n",
    "            \n",
    "\n",
    "    with open('data.toml', 'w') as _f:\n",
    "        _vars = %who_ls\n",
    "        _d = {\n",
    "            k: v\n",
    "            for k in _vars\n",
    "            if not inspect.ismodule((v := globals()[k]))\n",
    "            and not inspect.isfunction(v)\n",
    "            and not k.startswith('_')\n",
    "            and not repr(v).startswith('<')\n",
    "            and not (type(v) == pd.DataFrame and type(v.columns) != pd.MultiIndex)\n",
    "            or type(v) == pint.facets.measurement.objects.Measurement\n",
    "            or type(v) == _temptype\n",
    "            # or type(v) == _temptype1\n",
    "        }\n",
    "        toml.dump(_d, _f, encoder=MyEncoder())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
